# 机器学习

# week 1

```python
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
%matplotlib inline

#构建模拟数据
x=[i for i in range(1000)]   #特征
y=[15*x**2 + 3 + random.gauss(0,1) for x in x]

print(x)
print(y)

# 探索性分析
plt.scatter(x,y)

# 构建神经网络模型
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1,input_shape=(1,)))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Dense(1))
#模型编译
model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
             loss = 'mse',
             metrics = ['mse'])

#可视化训练过程
plt.plot(history.epoch[20:],history.history.get('loss')[20:])
```

如果在 X 与 y 的关系中，如果是一次的关系，这个地方是构建一个神经网络模型

```python
# 构建神经网络模型
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1,input_shape=(1,)))
model.add(tf.keras.layers.Dense(1))
```

如果是二次模型的话，就构建两个神经网络模型：

```python
# 构建神经网络模型
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(1,input_shape=(1,)))
model.add(tf.keras.layers.Dense(1))
model.add(tf.keras.layers.Dense(1))
```

![](https://wx4.sinaimg.cn/large/008uF2zMly8h5upotvuzvj30ac07774q.jpg)

![](https://wx1.sinaimg.cn/large/008uF2zMly8h5upotwqdwj30a2077jrk.jpg)

无监督学习相对监督学习而言，有以下特点：

- 无需大量的标注数据，从而减少大量的人力、物力和财力
- 以更加接近人类的学习方式不断自我发现、学习和调整，有利于发现世界的内在结果，找到新的模式或新的知识。

常见的无监督学习算法有聚类、关联分析等



# week 2 



万能逼近原理：MLP 能够逼近任何函数，如果逼近的效果不好，可以增加几个节点或者多加几层。



[绘制神经网络的网址](http://alexlenail.me/NN-SVG/)

[markdown grammar](https://markdown.com.cn/basic-syntax/links.html)



训练完之后保存模型：

```python
#训练模型，训练过程保存在history中
ck_pt_cb = tf.keras,callbacks.ModelCheckpoint("best_model.h5",save_best_only = True)
ck_pt_cb = tf.keras,callbacks.EarlyStopping(patience = 10,restore_best_weights = True )
```



```python
tf.keras.models.save_model(model,'hh.h5')
```

查看 `Tensorflow` 版本：`print('Tensorflow Version:{}'.format(tf.__version__))`


# week 3
损失函数：也叫代价函数，是线性回归常用来检测误差的指标。
代价函数是我们需要了解的：一个是假设函数，一个是代价函数




