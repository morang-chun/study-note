

引言
> 我们经常需要将多个Excel文件，或者从多个渠道获得来的数据综合起来一起分析。

[TOC]

## 数据的合并

数据合并主要包括下面两种操作：

轴向连接（concatenation）：`pd.concat()`可以沿一个轴将多个`DataFrame`对象连接在一起，形成一个新的`DataFrame`对象。

融合（merging）：`pd.merge()`方法可以根据一个或多个键将不同`DataFrame`中的行连接起来。

`concat()`函数可以将数据根据不同的轴进行合并。我们先看一下`concat()`的常用参数：

- `pd.concat(objs, axis=0, join='outer')`
- axis： 需要合并连接的轴，0是行，1是列，默认是0
- objs: series、dataframe 或者是 panel 构成的序列list
- join：连接的方式 inner，或者outer，默认是 outer



当`concat()`使用默认参数合并df1和df2时：

`pd.concat(objs, axis=0, join='outer')`

```python
import pandas as pd
dict1 = {
    'A':['A0','A1','A2','A3'],
    'B':['B0','B1','B2','B3'],
    'C':['C0','C1','C2','C3']
}
df1 = pd.DataFrame(dict1)

dict2 = {
    'B':['B0','B1','B2','B3'],
    'C':['C0','C1','C2','C3'],
    'D':['D0','D1','D2','D3']
}
df2= pd.DataFrame(dict2)
print(df1)
print(df2)
```

```tex
    A   B   C
0  A0  B0  C0
1  A1  B1  C1
2  A2  B2  C2
3  A3  B3  C3
    B   C   D
0  B0  C0  D0
1  B1  C1  D1
2  B2  C2  D2
3  B3  C3  D3
```

```python
pd.concat([df1,df2],join='outer')
```

<img src="https://s2.loli.net/2022/10/30/9V4A6E5d3az8YSu.png" alt="image.png" style="zoom:2%;" />

```python
pd.concat([df1,df2],axis=1,join='outer')
```

<img src="https://s2.loli.net/2022/10/30/da2Q6NcYS9oLsUO.png" alt="image.png" style="zoom:25%;" />

通过上面的结果可以发现，当`join='outer'`，axis参数为0时，列进行并集处理，纵向表拼接，缺失值由 NaN 填充，并且会保留原有数据的行索引。代码片段`pd.concat(objs, axis=0, join='outer')`

01.如果两个表的index都没有实际含义，使用`ignore_index`参数，置true，重新整理一个新的index。

02.代码实现:`pd.concat([df1,df2],axis=0,join='outer',ignore_index=True)`

03.当`concat()`的axis参数为1合并df1和df2时：

04.代码实现:`pd.concat([df1,df2],axis=1,join='outer')`

05.当`join='outer'`，axis参数为1时，行进**行**并集处理，横向表拼接，缺失值由NaN填充。

当`concat()`的join参数为inner时合并df1和df2时：`pd.concat([df1,df2],axis=0,join='inner')`

<img src="https://s2.loli.net/2022/10/30/BKkOTU1ugvFPNGt.png" alt="image.png" style="zoom: 25%;" />

通过上面的结果可以看出，如果为inner，得到的是两表的交集，如果是outer，得到的是两表的并集。

参数介绍

merge()函数通过指定连接键拼接列数据，我们先看一下

merge的常用参数：代码片段`merge(left, right, how='inner', on=None)`

1. left和right：两个要合并的DataFrame

2. how：连接方式，有inner、left 、 right 、 outer ， 默为inner

3. on：指的是用于连接的列索引名称，必须存在于左右两个DataFrame中，如果没有指定且其他参数也没有指定，则以两个DataFrame列名交集作为连接键.

```python
left = pd.DataFrame({
    'key':['a','b','b','d'],'data1':range(4)
})

right = pd.DataFrame({'key':['a','b','c'],'data2':range(3)})
print(left)
print(right)
```

<img src="https://s2.loli.net/2022/10/30/dK6ERFeZvBYNiHC.png" alt="image.png" style="zoom:2%;" />





当merge()使用默认参数连接两个DataFrame时：`pd.merge(left, right)`

merge()默认做inner连接，并且使用两个DataFrame的列名交集（key）作为连接键，同样，最终连接的数据也是两个DataFrame    key列数据的交集。代码片段pd.merge(left, right)

<img src="https://s2.loli.net/2022/10/30/CdnEBT4yF9Kh5fi.png" alt="image.png" style="zoom:25%;" />

当两个DataFrame使用做outer连接时：`pd.merge(left,right,on=['key'],how='outer')`

![image.png](https://s2.loli.net/2022/10/30/yGVh496NAkjMdXC.png)

当merge()做outer连接时最终连接的数据是两个DataFramekey列数据的并集，缺失的内容由NaN填充。

当两个DataFram使用left做连接时：`pd.merge(left,right,on=['key'],how='left')`

当merge()做left连接时，最终连接的数据将以left数据的链接键为准合并两个数据的列数据，缺失的内容由NaN填充

![image.png](https://s2.loli.net/2022/10/30/GERSpyeFUlYLXja.png)

那么，当merge()做right连接时，最终的链接数据是什么样呢？运行下面的代码，验证你的想法：

`pd.merge(left,right,on=['key'],how='right')`

![image.png](https://s2.loli.net/2022/10/30/NGFilMBJEw9KZAc.png)

## 数据的筛选

> 我们学习了如何获取一条数据或者连续的多条数据，但是实际工作中我们经常需要处理上万条数据，特别是合并后的数据甚至上亿条，那么我们如何能快速筛选出符合条件的数据呢?

![image.png](https://s2.loli.net/2022/10/30/SnzGdDWACkPpKaF.png)

了解了数据的基本情况之后，第一个需求是将关注者超过100的用户数据获取出来。

我们先来看看筛选逻辑，然后运行代码，验证筛选结果：

![image.png](https://s2.loli.net/2022/10/30/QnCgxK7Nb9dvH4O.png)

我们已经准确获取到所有关注者超过100的用户数据，下面我们看一下代码的逻辑。

代码片段:

`bools= df['关注者']>100`首先判断每个用户的关注者数量是否大于100，大于则会返回True，表示该行被标记为True，否则被标记为False。bools记录了每一行是否符合筛选条件，是一个Series对象，其中的值是bool类型。

`df1 = df[bools]`    然后，根据bools每行的值来对df进行筛选，值为True，表示对应的行会留下，否则，则去除。

最后打印的df1数据就是关注者超过100的用户数据。这是pandas根据某列的值进行筛选的基本逻辑。

**多条件的联合筛选**

第二个需求是：获取关注者超过300并且关注的超过100的用户数据。

运行下面的代码。

![image.png](https://s2.loli.net/2022/10/30/qg9eDwKSucb7NpZ.png)

上面的这段代码里，我们通过了2个限制条件

df['关注者']>300     和     df['关注']>100，分别得到 bool1和bool2这2个Series。

在我们的需求中，需要的数据是同时满足两个条件，所以我们使用逻辑与运算连接两个值，最后获取同时满足两个条件的值。

## 数据的排序

### 总结sort_values函数的用法

python中默认按行索引号进行排序，如果要自定义数据框的排序，可以用sort_values函数进行重定义排序。下面对sort_values中几个常用的参数进行讲解，它的具体语法如下：

`sort_values(by=[列表],ascending=[True or False], axis=(1 or 0),inplace=True or False)`

- `inplace=True`参数和我们之前见过的作用一样，用来控制是否直接对原始数据进行修改。

- `ascending`可以控制排序的顺序，默认值为True从小到大排列，当它被设置为False的时候就可以实现倒序排列。

- `ascending=False`:将数据按照从大到小的顺序排列。

- `inplace=True`:用来控制是否直接对原始数据进行修改。

- `by`:决定了是按数据中的哪一列进行排序，将需要按照某列排序的列名赋值给by即可。



若想按年龄升序身高降序排列数据框，可在python中输入如下语句：

```python
date_frame.sort_values(by = ['age','height'], ascending = [True,False])
```

![](https://img-blog.csdnimg.cn/20201203214521346.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNTMyNjYz,size_16,color_FFFFFF,t_70#pic_center)



## 总结

**数据合并**

| 方法        | 说明                                                 |
| ----------- | ---------------------------------------------------- |
| pd.concat() | 沿一个**轴**将多个 DataFrame 对象连接在一起          |
| axis        | 参数值：0表示行，1表示列                             |
| join        | outer 并集处理，inner 交集出来                       |
| merge()     | 通过指定连接拼接列数据                               |
| how         | 连接方式，有 inner，left，right，outer，默认为 inner |
| on          | 指定是要于连接的列索引名称                           |



**数据筛选**

| 方法              | 说明                                         |
| ----------------- | -------------------------------------------- |
| df['列名']>100    | 返回每一行是否符合该条件的bool类型的series   |
| df[bool1 & bool2] | 如果对个条件可以将判断条件之间使用逻辑运算符 |

**数据排序**

| 方法                     | 说明                                         |
| ------------------------ | -------------------------------------------- |
| sort_index()             | 是按照行索引进行排序                         |
| sort_values()            | 可以指定具体列进行排序                       |
| sort_values() 的 by 参数 | 决定了是按数据中的哪一列进行排序             |
| ascending = False        | 将数据按照从大到小的顺序排列，默认True，升序 |
| inplace = True           | 用来控制是否直接对原始数据进行修改           |

## 数据分组

SQL经常将[聚合函数](https://so.csdn.net/so/search?q=聚合函数&spm=1001.2101.3001.7020)与GROUP BY进行组合，对数据进行分组统计分析，python在分析数据中也可以实现相同的功能，而且python也是用GROUPBY

首先创建一个数据表:

```python
import pandas as pd
import numpy as np
 
value = {'用户ID':['001','002','003','004','005','006'],
         '用户类型':['大','小','中','大','小','中'],
         '区域':['A','B','A','C','B','A'],
         '7月销量':[50,60,75,100,120,130],
         '7月销售额':[500,1200,2250,1100,3600,5200]}
df = pd.DataFrame(value)
```

<img src="https://s2.loli.net/2022/10/30/qmlLJF5VYHgD7Mf.png" alt="image.png" style="zoom:67%;" />



### 1.groupby()

最重要的参数为by

其他参数根据情况，一般默认即可， axis=0, level=None，as_index=True，sort = True, group_keys= True, observed= False, dropna= True

如果是基于单列进行分组，括号中可以填入列名，如'用户类型'，也可以填入Series，如df['用户类型']
如果是基于多列进行分组，括号中可以填入列名组成的**列表**，如["用户类型","区域"]，也可以填入Series组成的列表，如[df["用户类型"],df["区域"]

`df.groupby(by='7月销量')`

<img src="https://s2.loli.net/2022/10/30/3cD7RrVHTWqpb8E.png" alt="image.png" style="zoom:67%;" />



### 2. 统计函数

1. 常见统计函数包括mean,sum,count,max,min等

```python
df.groupby(['用户类型','区域']).sum()
```

<img src="https://s2.loli.net/2022/10/30/rIxc9ylASudGYk6.png" alt="image.png" style="zoom:67%;" />

2. 对选择出来的列进行多种统计，此时需要借助aggregate方法，对分组后选择的列**同时进行多种统计**

```python
df.groupby(['用户类型','区域']).aggregate(['sum','count'])
```

<img src="https://s2.loli.net/2022/10/30/QlfBSsj1hoeCJgv.png" alt="image.png" style="zoom:80%;" />

3. 对选择出来的列，不同列进行不同的统计，如一个列进行求和，一个列进行求平均，仍需要借助aggregate方法，不过这个时候需要传入以列名为键，统计函数为值的**字典**

```python
df.groupby(['用户类型','区域']).aggregate({'7月销量':'sum','7月销售额':'mean'})
```

<img src="https://s2.loli.net/2022/10/30/Ok9BYGa1mMoRHh2.png" alt="image.png" style="zoom:80%;" />

### 3.索引处理

默认以分组中的某列或某些列为索引，但有时候我们并不想要这样的索引，此时有两种方法处理：

- 将groupby()中的参数as_index设置为False，即as_index=False

```python
df.groupby('用户类型',as_index=False).sum()
```
![image.png](https://s2.loli.net/2022/10/30/ePXNlMjrmBi9OdF.png)

- 通过reset_index()重置索引
```python
  df.groupby('用户类型').sum().reset_index()
```

  ![image.png](https://s2.loli.net/2022/10/30/ePXNlMjrmBi9OdF.png)



## 对分组进行遍历

上面我们通过`groupby()`和`size()`两个方法以及以前所学的一些技能计算出了富豪的男女占比。

如果我们还想要分别查看富豪中男、女的最大年纪，最小年纪以及平均年龄，看看我们是不是还有机会成为他们中的一员。

`groups.get_group('F')`可以获取分组后某一个组的数据，'F'为组的名字，这样我们就可以对某一个组进行处理。

![image.png](https://s2.loli.net/2022/10/31/VDrqJcblG8zpFaf.png)

下面的代码实现了获取'F'组的最大年纪，最小年纪以及平均年龄，运行代码并观察结果。

![image.png](https://s2.loli.net/2022/10/31/L1nag9ZNOSRY4rP.png)



代码中我们使用get_group()获取了F组的数据，并使用mean()、max()、min()等统计函数快速获取我们的指标值。

| 函数      | 意义                     |
| --------- | ------------------------ |
| count()   | 统计列表中非空数据的个数 |
| nunique() | 统计非重复的数据的个数   |
| sum()     | 统计列表中所有数值的和   |
| mean()    | 计算列表中数据的平均值   |
| median()  | 统计列表的数据的在中位数 |
| max()     | 求列表中数据的最大值     |
| min()     | 求列表中数据的最小值     |

上面的代码成功的计算出了我们想要的数据，我们也可以遍历分组后的数据，并获取他们的最大年纪，最小年纪以及平均年龄。

运行下面的代码，看一下如何遍历分组后的数据。



上面代码中的将分组后的对象groups进行遍历，可以获取到group_name每个组的名字，group_df每个组的数据



接下来我们自己在下面代码框中练习使用遍历的方法，计算出每一组中的最大年纪，最小年纪以及平均年龄。

![image.png](https://s2.loli.net/2022/10/31/ArblReiOhXCg83s.png)

### 按多列进行分组

> 刚刚我们完成了将富豪以性别进行分组，并拿到了年龄的最大值和最小值以及平均值等信息。
>
> 现在我们完成一个相对复杂的需求，需要查看每个国家男女的富豪的 数量。那就需要我们将富豪们先按国家分组，然后在按性别分组。。

按照上面的分析，难道我们要写两次`groupby`的分组操作？NO，我们强大 的`groupby()` 方法是支持按照多列进行分组。

运行上面的代码，看下`groupby()`是如何进行多列分组的：

```python
group = df.groupby(['country','gender'])
df1 = group.size()
print(df1)
```



当需要按多列进行分组的时候，`groupby()`方法里面我们传入的一个列表，列表中分别存储分组依据的列名。

**注意：列表中列名的顺序，确定了先按country列进行分组，然后再按gender列分组。不同的顺序，产生的分组名字是不同的。**

 `group.size()`返回的结果中发现索引值是多层的，那么

对于多层索引的值我们如何去获取呢？

```python
group = df.groupby(['country','gender'])
df1 = group.size()
print(df1)
size = df1['Austria']['F']
print(size)
```

通过代码，我们发现对于多层索引值的获取，只需要从外往里一层一层的取就可以了.

## 分组后统计

> 数据统计（也称为数据聚合）是数据处理的最后一步，通常是要使每一个数组生成一个单一的数值。

上面我们已经了解了一些Pandas提供好的统计函数，例 如 :mean() 、max() 等函数 。

为大家使用更为灵活 ，pandas提供了一个 `agg( )`方法用来对分组后的数据进行统计。

接下来我们来体验一下，`agg()`方法的使用：

```python
import pandas as pd
df = pd.read_excel("")
groups = df.groupby('gender')
for goup_name,group_id in groups:
    f_se = group_df['agg'].agg(['max','min','mean'])
    prnt('{}组的最大年龄是{}，最小年龄是{},平均年龄是{}'.format(group_name,f_se[0],f_se[1],f_se[2])
```

观察上面的代码，可以发现在使用`agg()`函数时，我们可以将多个统计函数一起放到一个`agg()`函数中。并且需要注意的是，如果是统计函数是pandas提供的，我们只需将函数的名字以字符串的形势存储到列表中即可

例如：将max()改成'max'。

这样不仅简化了我们的代码，在添加和删减统计函数的时候我们只需更改`agg()`函数中list就可以了。是不是很方便。它的好处还不止这些，比如现在又有新的需求，要计算年龄的最大值和最小值的差值。但是，pandas并没有提供这样统计函数，所以就需要我们进行自己定义一个统计函数：

```python
def peak_range(df):
    """
    返回数值范围
    """
    return df.max()-df.min()
```

现在我们看一下自己定义的统计函数，如何使用

```python
import pandas as pd
df = pd.read_excel("")
groups = df.groupby('gender')
def peak_range(df):
    """
    返回数值范围
    """
    return df.max()-df.min()

for goup_name,group_id in groups:
    f_se = group_df['agg'].agg(['max','min','mean',peak_range()])
    print(f_se[0],f_se[1],f_se[3])
```

peak_range(df)函数是我们自定的函数，并设置了一个df参数,为了接收group_df['age']的值。

注意：自定义的函数名字在传入agg()函数中时不需要转换成字符串。



## 总结

**数据分组**

- 使用`groupby()`方法进行分组
- `group.size()`查看分组后每组的数量
- `group.groups()`查看分组情况
- `group.get_group('F')`根据分组后的名字选择分组数据

**对分组进行遍历**

- 使用 for …in…可以对分组后的对象进行遍历
- 遍历时刻获取两个对象，分组后的名字和对应的数据

**按多列进行分组**

- 使用`groupby()`方法进行按多列分组
- 将多个列名放到列表中传给`groupby()`做参数
- 分组后的数据会有多层索引，获取数据需要从外到里逐层获取

