

> 我们经常需要将多个Excel文件，或者从多个渠道获得来的数据综合起来一起分析。
>

## 数据的合并

数据合并主要包括下面两种操作：

轴向连接（concatenation）：`pd.concat()`可以沿一个轴将多个`DataFrame`对象连接在一起，形成一个新的`DataFrame`对象。

融合（merging）：`pd.merge()`方法可以根据一个或多个键将不同`DataFrame`中的行连接起来。

`concat()`函数可以将数据根据不同的轴作进行合并。我们先看一下`concat()`的常用参数：

- `pd.concat(objs, axis=0, join='outer')`
- axis： 需要合并链接的轴，0是行，1是列，默认是0
- objs: series、dataframe或者是panel构成的序列list
- join：连接的方式inner，或者outer，默认是outer

当`concat()`使用默认参数合并df1和df2时：

`pd.concat(objs, axis=0, join='outer')`

通过上面的结果可以发现，当`join='outer'`，axis参数为0时，列进行并集处理，纵向表拼接，缺失值由 NaN 填充，并且会保留原有数据的行索引。代码片段`pd.concat(objs, axis=0, join='outer')`

![](https://wx1.sinaimg.cn/large/008uF2zMgy1h6dda48x7yj30co0alwft.jpg)

01.如果两个表的index都没有实际含义，使用`ignore_index`参数，置true，重新整理一个新的index。

02.代码实现

`pd.concat([df1,df2],axis=0,join='outer',ignore_index=True)`

03.当`concat()`的axis参数为1合并df1和df2时：

04.代码实现

`pd.concat([df1,df2],axis=1,join='outer')`

05.当`join='outer'`，axis参数为1时，行进行并集处理，横向表拼接，缺失值由NaN填充。

当`concat()`的join参数为inner时合并df1和df2时：`pd.concat([df1,df2],axis=0,join='inner')`

通过上面的结果可以看出，如果为inner，得到的是两表的交集，如果是outer，得到的是两表的并集。

参数介绍

merge()函数通过指定连接键拼接列数据，我们先看一下

merge的常用参数：代码片段`merge(left, right, how='inner', on=None)`

1. left和right：两个要合并的DataFrame

2. how：连接方式，有inner、left 、 right 、 outer ， 默为inner

3. on：指的是用于连接的列索引名称，必须存在于左右两个DataFrame中，如果没有指定且其他参数也没有指定，则以两个DataFrame列名交集作为连接键.

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6dda57t3oj30iv0btjsx.jpg)

当merge()使用默认参数连接两个DataFrame时：`pd.merge(left, right)`

merge()默认做inner连接，并且使用两个DataFrame的列名交集（key）作为连接键，同样，最终连接的数据也是两个DataFramekey列数据的交集。代码片段pd.merge(left, right)

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6dda5ipszj30dp0c7dho.jpg)

当两个DataFram使用做outer连接时：`pd.merge(left,right,on=['key'],how='outer')`

![](https://wx1.sinaimg.cn/large/008uF2zMgy1h6dda5wcu0j30cw0bgmyp.jpg)

当merge()做outer连接时最终连接的数据是两个DataFramekey列数据的并集，缺失的内容由NaN填充。

当两个DataFram使用left做连接时：`pd.merge(left,right,on=['key'],how='left')`

当merge()做left连接时，最终连接的数据将以left数据的链接键为准合并两个数据的列数据，缺失的内容由NaN填充

![](https://wx2.sinaimg.cn/large/008uF2zMgy1h6dda6acg9j30bd0bd758.jpg)

那么，当merge()做right连接时，最终的链接数据是什么样呢？运行下面的代码，验证你的想法：

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6dda6nofsj30lt073dhm.jpg)

## 数据的筛选

> 我们学习了如何获取一条数据或者连续的多条数据，但是实际工作中我们经常需要处理上万条数据，特别是合并后的数据甚至上亿条，那么我们如何能快速筛选出符合条件的数据呢?

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6ddu6teu1j30oq08m41g.jpg)

了解了数据的基本情况之后，第一个需求是将关注者超过100的用户数据获取出来。

我们先来看看筛选逻辑，然后运行代码，验证筛选结果：

![](https://wx1.sinaimg.cn/large/008uF2zMgy1h6ddu74xfjj30m70ax42a.jpg)

我们已经准确获取到所有关注者超过100的用户数据，下面我们看一下代码的逻辑。

代码片段:

`bools= df['关注者']>100`首先判断每个用户的关注者数量是否大于100，大于则会返回True，表示该行被标记为True，否则被标记为False。bools记录了每一行是否符合筛选条件，是一个Series对象，其中的值是bool类型。

`df1 = df[bools]`    然后，根据bools每行的值来对df进行筛选，值为True，表示对应的行会留下，否则，则去除。

最后打印的df1数据就是关注者超过100的用户数据。这是pandas根据某列的值进行筛选的基本逻辑。

**多条件的联合筛选**

第二个需求是：获取关注者超过300并且关注的超过100的用户数据。

运行下面的代码。

![](https://wx2.sinaimg.cn/large/008uF2zMgy1h6ddu7g1gzj30lk0900w6.jpg)

上面的这段代码里，我们通过了2个限制条件

df['关注者']>300     和     df['关注']>100，分别得到 bool1和bool2这2个Series。

在我们的需求中，需要的数据是同时满足两个条件，所以我们使用逻辑与运算连接两个值，最后获取同时满足两个条件的值。

## 数据的排序

使用的世界年龄抚养比率数据为行索引排序实验数据

![](https://wx1.sinaimg.cn/large/008uF2zMgy1h6ddu7r56fj30j00ebq6i.jpg)

根据国家名称来进行排序，并且Country Code这一列被设置成了行索引

![](https://wx2.sinaimg.cn/large/008uF2zMgy1h6ddu8521wj30ol0a7dje.jpg)

通过结果发现，原来排序这么简单！接下来我们一起分析一下代码。

`read_excel()`中的参数`index_col='Country Code'`作用是在读取文件的时候指定Country Code这一列数据为行索引。

`inplace=True`参数和我们之前见过的作用一样，用来控制是否直接对原始数据进行修改。

`ascending`可以控制排序的顺序，默认值为True从小到大排列，当它被设置为False的时候就可以实现倒序排列。



`ascending=False`:将数据按照从大到小的顺序排列。

`inplace=True`:用来控制是否直接对原始数据进行修改。

by:决定了是按数据中的哪一列进行排序，将需要按照某列排序的列名赋值给by即可。

## 总结

**数据合并**

| 方法        | 说明                                                 |
| ----------- | ---------------------------------------------------- |
| pd.concat() | 沿一个轴将多个 DataFrame 对象连接在一起              |
| axis        | 参数值：0表示行，1表示列                             |
| join        | outer 并集处理，inner 交集出来                       |
| merge()     | 通过指定连接拼接列数据                               |
| how         | 连接方式，有 inner，left，right，outer，默认为 inner |
| on          | 指定是要于连接的列索引名称                           |



**数据筛选**

| 方法              | 说明                                         |
| ----------------- | -------------------------------------------- |
| df['列名']>100    | 返回每一行是否符合该条件的bool类型的series   |
| df[bool1 & bool2] | 如果对个条件可以将判断条件之间使用逻辑运算符 |

**数据排序**

| 方法                     | 说明                                         |
| ------------------------ | -------------------------------------------- |
| sort_index()             | 是按照行索引进行排序                         |
| sort_values()            | 可以指定具体列进行排序                       |
| sort_values() 的 by 参数 | 决定了是按数据中的哪一列进行排序             |
| ascending = False        | 将数据按照从大到小的顺序排列，默认True，升序 |
| inplace = True           | 用来控制是否直接对原始数据进行修改           |

## 数据分组

本节我们将以福布斯2018年度亿万富翁数据为实验数据，探索数据分组的奥秘，运行下面的代码，来了解一下数据的基本情况：

![](https://wx2.sinaimg.cn/large/008uF2zMgy1h6depr70cdj30ja06cq4o.jpg)

数据详情：name-名字、lastName-姓、age-年龄、country-国家、 gender-性别、wealthSource-财富来源。

根据结果我们了解到，共有2031条数据，那么在这些富翁中男女比例是多少呢？要解决这个问题，我们最好的办法就是根据性别分成男女两组，然后分别计算他们的人数，从而计算他们的占比。

Pandas提供了一个灵活高效的groupby功能，它使你能以一种自然的方式对数据集进行切片、切块、摘要等操作。

我们一起看下如何使用groupby()方法根据性别将富翁们进行分组，运行下方代码，查看结果。

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6deprjo48j30k404hwfk.jpg)

核心代码：`groups = df.groupby('gender')`

根据结果可以发现，分组后的结果为`DataFrameGroupBy object`，是一个分组后的对象。

用`groupby`的size方法可以查看分组后每组的数量，并返回一个含有分组大小的Series：

代码片段:`print(groups.size())`

![](https://wx4.sinaimg.cn/large/008uF2zMgy1h6deprswf1j30a407nwel.jpg)

**如何获取男女的占比是多少**

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6deps4iv3j30ms091adw.jpg)

`df.groupby('gender')`是根据gender列对整个数据进行分组，同样我们也可以只对一列数据进行分组，只保留我们需要的列数据。

例如：我们通过性别gender，只对age列数据进行分组。

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6depsef45j30bo07075a.jpg)

01.将上面代码补全复制到左面的代码框，运行查看结果：

02.代码`df['age'].groupby(df['gender'])`的逻辑是：取出df中age列数据，并且对该列数据根据`df['gender']`列数据进行分组操作。

03.上一步的代码也可改写成`df.groupby(df['gender'])['age']`，它的逻辑是：将df数据通过`df['gender']`进行分组，然后再取出分组后的age列数据。两种写法达到的效果是一样的。

4. `group.groups`的结果是一个字典，字典的key是分组后每个组的名字，对应的值是分组后的数据，此方法方便我们查看分组的情况。

5. `group.get_group('F')`这个方法可以根据具体分组的名字获取，每个组的数据

## 对分组进行遍历

上面我们通过groupby()和size()两个方法以及以前所学的一些技能计算出了富豪的男女占比。

如果我们还想要分别查看富豪中男、女的最大年纪，最小年纪以及平均年龄，看看我们是不是还有机会成为他们中的一员。

groups.get_group('F')可以获取分组后某一个组的数据，'F'为组的名字，这样我们就可以对某一个组进行处理。

下面的代码实现了获取'F'组的最大年纪，最小年纪以及平均年龄，运行代码并观察结果。

![](https://wx1.sinaimg.cn/large/008uF2zMgy1h6deptk47kj30lt08ytb8.jpg)

代码中我们使用get_group()获取了F组的数据，并使用mean()、max()、min()等统计函数快速获取我们的指标值。

| 函数      | 意义                     |
| --------- | ------------------------ |
| count()   | 统计列表中非空数据的个数 |
| nunique() | 统计非重复的数据的个数   |
| sum()     | 统计列表中所有数值的和   |
| mean()    | 计算列表中数据的平均值   |
| median()  | 统计列表的数据的在中位数 |
| max()     | 求列表中数据的最大值     |
| min()     | 求列表中数据的最小值     |

上面的代码成功的计算出了我们想要的数据，我们也可以遍历分组后的数据，并获取他们的最大年纪，最小年纪以及平均年龄。

运行下面的代码，看一下如何遍历分组后的数据。

![](https://wx4.sinaimg.cn/large/008uF2zMgy1h6deptukbuj30tb08gjtu.jpg)

上面代码中的将分组后的对象groups进行遍历，可以获取到group_name每个组的名字，group_df每个组的数据



接下来我们自己在下面代码框中练习使用遍历的方法，计算出每一组中的最大年纪，最小年纪以及平均年龄。

![](https://wx3.sinaimg.cn/large/008uF2zMgy1h6depu6ibnj31170b4n2n.jpg)

### 按多列进行分组

> 刚刚我们完成了将富豪以性别进行分组，并拿到了年龄的最大值和最小值以及平均值等信息。
>
> 现在我们完成一个相对复杂的需求，需要查看每个国家男女的富豪的 数量。那就需要我们将富豪们先按国家分组，然后在按性别分组。。

按照上面的分析，难道我们要写两次`groupby`的分组操作？NO，我们强大 的`groupby()` 方法是支持按照多列进行分组。

运行上面的代码，看下`groupby()`是如何进行多列分组的：

```python
group = df.groupby(['country','gender'])
df1 = group.size()
print(df1)
```



当需要按多列进行分组的时候，`groupby()`方法里面我们传入的一个列表，列表中分别存储分组依据的列名。

**注意：列表中列名的顺序，确定了先按country列进行分组，然后再按gender列分组。不同的顺序，产生的分组名字是不同的。**

 `group.size()`返回的结果中发现索引值是多层的，那么

对于多层索引的值我们如何去获取呢？

```python
group = df.groupby(['country','gender'])
df1 = group.size()
print(df1)
size = df1['Austria']['F']
print(size)
```

通过代码，我们发现对于多层索引值的获取，只需要从外往里一层一层的取就可以了.

## 分组后统计

> 数据统计（也称为数据聚合）是数据处理的最后一步，通常是要使每一个数组生成一个单一的数值。

上面我们已经了解了一些Pandas提供好的统计函数，例 如 :mean() 、max() 等函数 。

为大家使用更为灵活 ，pandas提供了一个 `agg( )`方法用来对分组后的数据进行统计。

接下来我们来体验一下，`agg()`方法的使用：

```python
import pandas as pd
df = pd.read_excel("")
groups = df.groupby('gender')
for goup_name,group_id in groups:
    f_se = group_df['agg'].agg(['max','min','mean'])
    prnt('{}组的最大年龄是{}，最小年龄是{},平均年龄是{}'.format(group_name,f_se[0],f_se[1],f_se[2])
```

观察上面的代码，可以发现在使用`agg()`函数时，我们可以将多个统计函数一起放到一个`agg()`函数中。并且需要注意的是，如果是统计函数是pandas提供的，我们只需将函数的名字以字符串的形势存储到列表中即可

例如：将max()改成'max'。

这样不仅简化了我们的代码，在添加和删减统计函数的时候我们只需更改`agg()`函数中list就可以了。是不是很方便。它的好处还不止这些，比如现在又有新的需求，要计算年龄的最大值和最小值的差值。但是，pandas并没有提供这样统计函数，所以就需要我们进行自己定义一个统计函数：

```python
def peak_range(df):
    """
    返回数值范围
    """
    return df.max()-df.min()
```

现在我们看一下自己定义的统计函数，如何使用

```python
import pandas as pd
df = pd.read_excel("")
groups = df.groupby('gender')
def peak_range(df):
    """
    返回数值范围
    """
    return df.max()-df.min()

for goup_name,group_id in groups:
    f_se = group_df['agg'].agg(['max','min','mean',peak_range()])
    print(f_se[0],f_se[1],f_se[3])
```

peak_range(df)函数是我们自定的函数，并设置了一个df参数,为了接收group_df['age']的值。

注意：自定义的函数名字在传入agg()函数中时不需要转换成字符串。



## 总结

**数据分组**

- 使用`groupby()`方法进行分组
- `group.size()`查看分组后每组的数量
- `group.groups()`查看分组情况
- `group.get_group('F')`根据分组后的名字选择分组数据

**对分组进行遍历**

- 使用 for …in…可以对分组后的对象进行遍历
- 遍历时刻获取两个对象，分组后的名字和对应的数据

**按多列进行分组**

- 使用`groupby()`方法进行按多列分组
- 将多个列名放到列表中传给`groupby()`做参数
- 分组后的数据会有多层索引，获取数据需要从外到里逐层获取

